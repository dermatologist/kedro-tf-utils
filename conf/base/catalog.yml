# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

tabular_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/test_dataset.csv

image_data:
  type: PartitionedDataSet
  dataset: pillow.ImageDataSet
  path: data/01_raw/imageset
  filename_suffix: ".jpg"

chexnet_model:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/06_models/densenet-chexnet


fusion_model:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/07_model_output/fusion

datasetinmemory:
  type: MemoryDataSet
  copy_mode: assign


text_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/test_report.csv

pretrained_embedding:
  type: text.TextDataSet
  filepath: data/04_feature/new_data_embed300.txt

vocab_json:
  type: json.JSONDataSet
  filepath: data/04_feature/vocab.json

word2vec_embedding:
  type: pickle.PickleDataSet
  filepath: data/06_models/word2vec-embedding.pkl

glove_embedding:
  type: pickle.PickleDataSet
  filepath: data/06_models/glove-embedding.pkl

cnn_text_model:
  type: pickle.PickleDataSet
  filepath: data/06_models/cnn_text_model.pkl

processed_text:
  type: pickle.PickleDataSet
  filepath: data/03_primary/processed-text.pkl

bert_model:
  type: kedro_tf_text.extras.datasets.bert_model_download.BertModelDownload
  preprocessor_url: "https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3"
  encoder_url: "https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4"

bert_model_saved:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/06_models/bert-tf
  load_args:
    compile: False
  save_args:
    overwrite: True
    include_optimizer: False

tabular_bert_trained:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/07_model_output/tabular-bert-trained